model:
  language_tower:
    _target_: models.towers.language_tower.LanguageTower
    model_name: meta-llama/Meta-Llama-3-8B
    max_new_tokens: 256
    is_frozen: true
    use_8bit: true
  perception_tower:
    _target_: models.towers.perception_tower.PerceptionTower
    model_name: ByteDance-Seed/UI-TARS-1.5-7B
    is_frozen: true
  action_tower:
    _target_: models.towers.action_tower.ActionTower
    policy_type: DiffusionPolicy
    hidden_dim: 256
    action_dim: 4
    is_frozen: false
  bridge:
    _target_: models.bridge.grounding_bridge.GroundingBridge
    type: CrossAttention
    num_layers: 4
    hidden_dim: 1024
training:
  lr:
    language_tower: 1.0e-05
    perception_tower: 1.0e-05
    action_tower: 0.0001
    bridge: 0.0001
  optimizer:
    _target_: torch.optim.AdamW
    lr: 0.0001
    weight_decay: 0.01
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 100
  loss_weights:
    action_loss: 1.0
    contrastive_loss: 1.0
  batch_size: 32
  num_epochs: 100
  grad_accumulation_steps: 1
  logging_steps: 10
project_name: GroundedInterfaceAgent
seed: 42
checkpoint_path: null
mode: train
instruction: Click the start button.
